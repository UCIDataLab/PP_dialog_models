{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data\n",
    "## File Paths\n",
    "Set the data paths (for training, only when it's available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "te_data_file = './mhd_sample_te.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression Models\n",
    "Loads the pre-trained model `./lrdialog_ovr.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from models import LogRegDialogModel\n",
    "\n",
    "lr = LogRegDialogModel(lr_type='ovr')\n",
    "lr.load_model(model_file=\"./lrdialog_ovr.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads test data and predicts using the loaded model. <br>\n",
    "Utterance-level results will be saved to an output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr.predict(te_data_file, verbose=1, output_filename=\"./utter_level_results_lrovr.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the scores to see the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr.result.scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also can print out the scores as csv and save it to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr.result.print_scores(filename='./result_in_diff_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. HMM on top of LR\n",
    "Running HMM requires you to have `base_model`, which should be trained in advance and given as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from models import HMMDialogModel\n",
    "hmmlr = HMMDialogModel(base_model=lr)\n",
    "hmmlr.load_model(model_file='hmmdialog_lrovr.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicts the output labels using HMM and Viterbi decoding. <br>\n",
    "Also outputs the utterance-level results to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hmmlr.predict_viterbi(te_data_file, output_filename=\"./utter_level_results_hmm_lrovr.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hmmlr.result.scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. HMM on top of other output probabilities\n",
    "\n",
    "If we have a set of results from another base model (independent model) that is trained somewhere else (e.g. output from RNN), <br>\n",
    "we can load the predictions and output probabilities and plug them into HMM. <br>\n",
    "They should be the result of the same data as `mhdtest`.\n",
    "- `predictions`:  Should have a list of sessions, where each session is a 2-d array with size `(N,T)`, where `N` is the number of utterances in the session and `T` is the number of topics (labels). Each entry is the $p(topic|utterance)$ in each session.  <br> Type: `list[ 2-d np.array[float] ]`.\n",
    "- `output_probs`: Should have a list of sessions, where each session is a list of utterance predictions within that session. <br> Type: `list[list[int]]` or `list[np.array[int]]`\n",
    "\n",
    "\n",
    "After loading predictions and probabilities, a base model object should have the following data\n",
    "and it can be plugged in as an argument to HMMDialogModel\n",
    "- base_model.result\n",
    "- base_model.result.output_prob\n",
    "- base_model.model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models import DialogModel, HMMDialogModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predfile = './sample_pred.pkl'\n",
    "outprobfile = './sample_prob.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not from RNN, but let's say we've loaded the results from RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnn = DialogModel()\n",
    "rnn.load_results(te_data_file, model_info=\"RNN\", marginals=None, predictions=predfile, output_probs=outprobfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hmmrnn = HMMDialogModel(base_model=rnn)\n",
    "hmmrnn.fit_model(tr_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hmmrnn.predict_viterbi(te_data_file, output_filename=\"./utter_level_results_hmm_rnn.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we should have the same result as the result at section 2. since we've loaded the same result from LR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hmmlr.result.scores"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
